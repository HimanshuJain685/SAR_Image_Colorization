{"cells":[{"cell_type":"code","execution_count":null,"id":"5d407020-4a58-452b-a798-4aecbb29d052","metadata":{"id":"5d407020-4a58-452b-a798-4aecbb29d052"},"outputs":[],"source":["import os\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","from skimage.metrics import structural_similarity as ssim\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"id":"5ea90cd4-2de3-4ab1-a9ee-e2ed171144c7","metadata":{"id":"5ea90cd4-2de3-4ab1-a9ee-e2ed171144c7"},"outputs":[],"source":["# Set the device to GPU if available, otherwise CPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Define paths for datasets and output directories\n","train_sar_dir = 'dataset/train/sar_tif'\n","train_gray_dir = 'dataset/train/gray_tif'\n","val_sar_dir = 'dataset/val/sar_tif'\n","val_gray_dir = 'dataset/val/gray_tif'\n","test_sar_dir = 'dataset/test/sar_tif'\n","test_gray_dir = 'dataset/test/gray_tif'\n","output_dir = 'output'\n","model_dir = 'models'\n","os.makedirs(output_dir, exist_ok=True)\n","os.makedirs(model_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"id":"36cc7eba-8aec-4cc4-92b9-5ae3bd9f8d0c","metadata":{"id":"36cc7eba-8aec-4cc4-92b9-5ae3bd9f8d0c"},"outputs":[],"source":["# Define Dataset class for SAR and grayscale images\n","class SARDataset(Dataset):\n","    def __init__(self, sar_dir, gray_dir, transform_sar=None, transform_gray=None):\n","        # Initialize directories and transformations\n","        self.sar_dir = sar_dir\n","        self.gray_dir = gray_dir\n","        self.transform_sar = transform_sar\n","        self.transform_gray = transform_gray\n","        # Collect image names from SAR directory\n","        self.image_names = [f for f in os.listdir(sar_dir) if f.endswith('.tif')]\n","\n","    def __len__(self):\n","        # Return the total number of samples\n","        return len(self.image_names)\n","\n","    def __getitem__(self, idx):\n","        # Load paired SAR and grayscale images by replacing '_s1' with '_s2' for grayscale\n","        sar_file = self.image_names[idx]\n","        gray_file = sar_file.replace('_s1', '_s2')\n","\n","        sar_image = Image.open(os.path.join(self.sar_dir, sar_file)).convert(\"L\")\n","        gray_image = Image.open(os.path.join(self.gray_dir, gray_file)).convert(\"L\")\n","\n","        # Apply transformations if specified\n","        if self.transform_sar:\n","            sar_image = self.transform_sar(sar_image)\n","        if self.transform_gray:\n","            gray_image = self.transform_gray(gray_image)\n","\n","        return sar_image, gray_image"]},{"cell_type":"code","execution_count":null,"id":"32bff8c7-6ab5-49d3-bdcf-c8bdbb60ec52","metadata":{"id":"32bff8c7-6ab5-49d3-bdcf-c8bdbb60ec52"},"outputs":[],"source":["# Define transformations to apply on SAR and grayscale images\n","transform_sar = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","transform_gray = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])"]},{"cell_type":"code","execution_count":null,"id":"e305d9b0-8c45-4fa0-95b3-9ac283d8f44d","metadata":{"id":"e305d9b0-8c45-4fa0-95b3-9ac283d8f44d"},"outputs":[],"source":["# Define the Despeckling Generator network\n","class DespecklingGenerator(nn.Module):\n","    def __init__(self):\n","        super(DespecklingGenerator, self).__init__()\n","        # Simple CNN architecture with three convolutional layers and ReLU activations\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1),\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":null,"id":"b5794712-6890-49f5-9f6a-dd5870ee0e71","metadata":{"id":"b5794712-6890-49f5-9f6a-dd5870ee0e71"},"outputs":[],"source":["# Define the Discriminator network\n","class Discriminator(nn.Module):\n","    def __init__(self, in_channels=1):\n","        super(Discriminator, self).__init__()\n","        # CNN architecture with LeakyReLU activations for binary classification\n","        self.model = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=0)\n","        )\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.model(x))"]},{"cell_type":"code","execution_count":null,"id":"41776633-c703-495c-956f-631267dafbd7","metadata":{"id":"41776633-c703-495c-956f-631267dafbd7"},"outputs":[],"source":["# Initialize models, optimizers, and loss functions\n","GD = DespecklingGenerator().to(device)\n","DD = Discriminator().to(device)\n","optimizer_GD = optim.Adam(GD.parameters(), lr=0.0001)\n","optimizer_DD = optim.Adam(DD.parameters(), lr=0.000002)\n","adversarial_loss = nn.BCELoss()  # Loss function for discriminator\n","pixel_loss = nn.L1Loss()  # Pixel-wise L1 loss for generator\n","lambda_adv = 0.05  # Weight for adversarial loss\n","\n","# Load train, validation, and test datasets\n","train_dataset = SARDataset(sar_dir=train_sar_dir, gray_dir=train_gray_dir, transform_sar=transform_sar, transform_gray=transform_gray)\n","val_dataset = SARDataset(sar_dir=val_sar_dir, gray_dir=val_gray_dir, transform_sar=transform_sar, transform_gray=transform_gray)\n","test_dataset = SARDataset(sar_dir=test_sar_dir, gray_dir=test_gray_dir, transform_sar=transform_sar, transform_gray=transform_gray)\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"ff247fd7-3829-4a6b-bca7-b34715431ab0","metadata":{"id":"ff247fd7-3829-4a6b-bca7-b34715431ab0"},"outputs":[],"source":["# Training loop with validation\n","num_epochs = 5\n","best_val_psnr = 0\n","for epoch in range(num_epochs):\n","    GD.train()\n","    DD.train()\n","    epoch_g_loss, epoch_d_loss = 0, 0\n","    for sar, gray in tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\"):\n","        sar, gray = sar.to(device), gray.to(device)\n","        despeckled = GD(sar)\n","\n","        # Discriminator training\n","        optimizer_DD.zero_grad()\n","        real_labels = torch.ones_like(DD(gray)).to(device)\n","        fake_labels = torch.zeros_like(real_labels).to(device)\n","\n","        real_loss = adversarial_loss(DD(gray), real_labels)\n","        fake_loss = adversarial_loss(DD(despeckled.detach()), fake_labels)\n","        d_loss = (real_loss + fake_loss) / 2\n","        d_loss.backward()\n","        optimizer_DD.step()\n","\n","        # Generator training\n","        optimizer_GD.zero_grad()\n","        g_adv_loss = adversarial_loss(DD(despeckled), real_labels)\n","        g_pix_loss = pixel_loss(despeckled, gray)\n","        g_loss = g_pix_loss + lambda_adv * g_adv_loss\n","        g_loss.backward()\n","        optimizer_GD.step()\n","\n","        # Accumulate losses for printing\n","        epoch_g_loss += g_loss.item()\n","        epoch_d_loss += d_loss.item()\n","\n","    # Validation PSNR calculation\n","    GD.eval()\n","    val_psnr = []\n","    with torch.no_grad():\n","        for sar, gray in val_loader:\n","            sar, gray = sar.to(device), gray.to(device)\n","            despeckled = GD(sar)\n","            despeckled_np = despeckled.squeeze().cpu().numpy()\n","            gray_np = gray.squeeze().cpu().numpy()\n","            val_psnr.append(psnr(despeckled_np, gray_np, data_range=gray_np.max() - gray_np.min()))\n","    avg_val_psnr = np.mean(val_psnr)\n","\n","    # Save best model based on validation PSNR\n","    if avg_val_psnr > best_val_psnr:\n","        best_val_psnr = avg_val_psnr\n","        torch.save({'GD': GD.state_dict()}, f\"{model_dir}/best_despeckling_model_1.pth\")\n","        print(f\"Saved best model with PSNR: {avg_val_psnr:.4f}\")\n","\n","    # Print epoch metrics\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] - GD Loss: {epoch_g_loss/len(train_loader):.4f}, DD Loss: {epoch_d_loss/len(train_loader):.4f}, Val PSNR: {avg_val_psnr:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"d6de52ed-f6c0-4b6c-9de1-c0b86676c381","metadata":{"id":"d6de52ed-f6c0-4b6c-9de1-c0b86676c381","outputId":"bc51179a-c251-4569-93e6-5b65394e4074"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average PSNR on test set: 12.6496\n","Average SSIM on test set: 0.0536\n"]}],"source":["# Testing and evaluation on test set\n","GD.eval()\n","psnr_values, ssim_values = [], []\n","with torch.no_grad():\n","    for sar, gray in test_loader:\n","        sar, gray = sar.to(device), gray.to(device)\n","        despeckled = GD(sar)\n","        despeckled_np = despeckled.squeeze().cpu().numpy()\n","        gray_np = gray.squeeze().cpu().numpy()\n","        psnr_values.append(psnr(despeckled_np, gray_np, data_range=gray_np.max() - gray_np.min()))\n","        ssim_values.append(ssim(despeckled_np, gray_np, data_range=gray_np.max() - gray_np.min()))\n","\n","# Calculate and print average PSNR and SSIM\n","avg_psnr = np.mean(psnr_values)\n","avg_ssim = np.mean(ssim_values)\n","print(f\"Average PSNR on test set: {avg_psnr:.4f}\")\n","print(f\"Average SSIM on test set: {avg_ssim:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"1ebb4066-5f95-4f4f-b657-dad0b6aa621e","metadata":{"id":"1ebb4066-5f95-4f4f-b657-dad0b6aa621e"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}